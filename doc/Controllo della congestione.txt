Per il controllo della congestione ho implementato un protocollo di tipo stop-and-wait con pipeline. La finestra di congestione viene aumentatata e diminuita secondo un protocollo AIMD (Additive Increase Multiplicative Decrease), utilizzando un fattore di crescita che viene configurato tramite la struct congestion_control. I parametri di questa struct possono essere impostati a tempo di esecuzione, tramite file con sintassi .ini, che definisce dimensione iniziale della finestra, dimensione massima della finestra e il fattore di crescita. Dopo aver stabilito la connessione, il mittente invia un pacchetto di negoziazione al destinatario indicando la dimensione della finestra di congestione, in cui verranno bufferizzati i pacchetti in arrivo per garantire l'arrivo in ordine degli stessi. Dopo che il destinatario accetta la dimensione della finestra, allora il mittente invia il numero di pacchetti stabilito e il destinatario invia un pacchetto ACK per ogni pacchetto ricevuto correttamente. Se tutti i pacchetti sono ricevuti correttamente allora il mittente aumenta la finestra di congestione e invia un nuovo pacchetto di negoziazione indicando la nuova dimensione della finestra, il destinatario accetta e cosi via. Nel caso in cui un pacchetto venga perso, rilevato tramite scadenza del timeout della ricezione dell'ACK, il mittente riduce la finestra di congestione e comunica il cambiamento al destinatario. Assumendo un probabilità di perdita di pacchetti $p$, l'efficienza del canale può essere calcolata secondo la seguente formula (supponendo che ci sia una sola connessione attiva):

formula del controllo di congestione

Nel file di configurazione inoltre potrà anche essere specificato il numero di connessioni attive che il server può supportare (deciso in base alla potenza del server). Se questo valore venisse impostato a 0, allora il server accetterà tutte le connessioni in arrivo.
